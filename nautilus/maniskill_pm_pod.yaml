apiVersion: v1
kind: Pod
metadata:
  name: maniskill-pm-pod-pranav-allegro
spec:
  # runtimeClassName: nvidia
  containers:
  - name: gpu-container
    image: dhbhatt/maniskill-experiments:latest
    command: ["/bin/bash", "-c"]
    args: 
      - |
        tail -f /dev/null 
    volumeMounts:
    - mountPath: /pers_vol
      name: pm-slow-vol2
    resources:
      limits:
        nvidia.com/gpu: "1"
        memory: "32G"
        cpu: "16"
      requests:
        nvidia.com/gpu: "1"
        memory: "32G"
        cpu: "8"
  restartPolicy: Never
  # affinity:
  #   nodeAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #       nodeSelectorTerms:
  #       - matchExpressions:
  #         - key: nvidia.com/gpu.product
  #           operator: In
  #           values:
  #           - RTX-3090
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 98
        preference:
          matchExpressions:
          - key: nvidia.com/gpu.product
            operator: In
            values:
            - "NVIDIA-A100-80GB-PCIe"
            - "NVIDIA-A100-SXM4-80GB"
            - "NVIDIA-A100-80GB-PCIe-MIG-1g.10gb"
            - "NVIDIA-A100-PCIE-40GB"
            - "NVIDIA-RTX-A6000"
            - "NVIDIA-RTX-A5000"
            - "NVIDIA-GeForce-RTX-4090"
            - "NVIDIA-GeForce-RTX-4080"
            - "NVIDIA-GeForce-RTX-3090-Ti"
            - "NVIDIA-GeForce-RTX-3090"
            - "NVIDIA-GeForce-RTX-3080-Ti"
            - "NVIDIA-GeForce-RTX-3080"
      - weight: 1
        preference:
          matchExpressions:
          - key: nvidia.com/gpu.product
            operator: In
            values:
            - "NVIDIA-A40"
            - "NVIDIA-A10"
            - "Tesla-V100-SXM2-32GB"
      - weight: 1
        preference:
          matchExpressions:
          - key: nvidia.com/gpu.product
            operator: In
            values:
            - "NVIDIA_TITAN_RTX"
            - "NVIDIA-RTX-A6000"
      - weight: 98
        preference:
          matchExpressions:
          - key: kubernetes.io/hostname
            operator: In
            values:
            - "ry-gpu-1.sdsc.optiputer.net"
            - "ry-gpu-2.sdsc.optiputer.net"
            - "ry-gpu-3.sdsc.optiputer.net"
            - "ry-gpu-4.sdsc.optiputer.net"
            - "ry-gpu-5.sdsc.optiputer.net"
            - "ry-gpu-6.sdsc.optiputer.net"
            - "ry-gpu-7.sdsc.optiputer.net"
            - "ry-gpu-8.sdsc.optiputer.net"
            - "ry-gpu-9.sdsc.optiputer.net"
            - "ry-gpu-10.sdsc.optiputer.net"
            - "ry-gpu-11.sdsc.optiputer.net"
            - "ry-gpu-12.sdsc.optiputer.net"
            - "ry-gpu-13.sdsc.optiputer.net"
            - "ry-gpu-14.sdsc.optiputer.net"
            - "ry-gpu-15.sdsc.optiputer.net"
            - "k8s-gpu-01.sdsc.optiputer.net"
            - "k8s-gpu-02.sdsc.optiputer.net"
            - "k8s-gpu-03.sdsc.optiputer.net"
            - "k8s-gpu-04.sdsc.optiputer.net"
            - "k8s-gpu-05.sdsc.optiputer.net"
            - "k8s-gpu-06.sdsc.optiputer.net"
            - "k8s-gpu-07.sdsc.optiputer.net"
            - "k8s-gpu-08.sdsc.optiputer.net"
            - "k8s-gpu-09.sdsc.optiputer.net"
            - "k8s-gpu-10.sdsc.optiputer.net"
            - "k8s-gpu-11.sdsc.optiputer.net"
            - "k8s-gpu-12.sdsc.optiputer.net"
            - "k8s-gpu-13.sdsc.optiputer.net"
            - "k8s-gpu-14.sdsc.optiputer.net"
            - "k8s-gpu-15.sdsc.optiputer.net"
            # - "k8s-haosu-02.sdsc.optiputer.net"
            # - "k8s-haosu-03.sdsc.optiputer.net"
            # - "k8s-haosu-04.sdsc.optiputer.net"
            # - "k8s-haosu-05.sdsc.optiputer.net"
            # - "k8s-haosu-06.sdsc.optiputer.net"
            # - "k8s-haosu-07.sdsc.optiputer.net"
            # - "k8s-haosu-08.sdsc.optiputer.net"
            # - "k8s-haosu-09.sdsc.optiputer.net"
            # - "k8s-haosu-10.sdsc.optiputer.net"
            # - "k8s-haosu-11.sdsc.optiputer.net"
            # - "k8s-haosu-12.sdsc.optiputer.net"
            # - "k8s-haosu-13.sdsc.optiputer.net"
            # - "k8s-haosu-14.sdsc.optiputer.net"
            # - "k8s-haosu-15.sdsc.optiputer.net"
            # - "k8s-haosu-16.sdsc.optiputer.net"
            # - "k8s-haosu-17.sdsc.optiputer.net"
            # - "k8s-haosu-18.sdsc.optiputer.net"
            # - "k8s-haosu-19.sdsc.optiputer.net"
            # - "k8s-haosu-20.sdsc.optiputer.net"
            # - "k8s-haosu-21.sdsc.optiputer.net"
            # - "k8s-haosu-22.sdsc.optiputer.net"
            # - "k8s-haosu-23.sdsc.optiputer.net"
  volumes:
    - name: pm-slow-vol2
      persistentVolumeClaim:
        claimName: pm-slow-vol2

#rm -rf mani_skill/ && \
        # git clone --recurse-submodules https://github.com/Pranav-Malpure/Image-based-RL-Manipulation && \
        # cd Image-based-RL-Manipulation/ManiSkill && \
        # git checkout xarm_allegro && \
        # mv mani_skill/ /workspace/ManiSkill/

        # nvidia/cuda:11.8.0-devel-ubuntu22.04
        # nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04 